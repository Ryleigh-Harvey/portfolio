# -*- coding: utf-8 -*-
"""Copy of NLP Machine Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C1zhQ07WVXvcmTUGbKiY68ZE32t3GFfk
"""





"""# Machine Learning project 1:
### James Maduako and Ryleigh Harvey

**Introduction**
The data sets we are using...

### Gender Definition Project:
 In our project we will be focusing on gauging a persons gender by their manner of speech using a twitter dataset and another dataset. We will be using various methods to assess the gender such as sentiment analysis, text clssification, svm and naive bayes to further assess the values and features.
"""

from google.colab import drive
import nltk
import pandas as pd
nltk.download('all')
drive.mount('/content/drive')
twitter = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Data/training.1600000.processed.noemoticon[1].csv', nrows=9000, header = 0,encoding='latin-1')
sentimentd = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Data/sentimentdataset.csv')

text = 'Hi, my name is James and I am endlesssly bored of life and of living. Do you want to build a snowman. I am so distraught.'
from nltk.corpus import names
#sentimentd.head()
new_columns = ['Target', 'ID','Date','Flag','User','Text']
twitter.columns = new_columns
twitter.head()

"""#### Classification
We first are gonna add a new column that will highlight the male and female values of the users based on a male and female name dataset. We will compare the user names with the male and female names to give
"""

labeled_names = ([(name, 'male') for name in names.words('male.txt')]+
             [(name, 'female') for name in names.words('female.txt')])
print(labeled_names)

male_names = list(names.words('male.txt'))
female_names = list(names.words('female.txt'))
males = [x.lower() for x in male_names]
females = [x.lower() for x in female_names]
new_data = twitter
new_data['gender'] = 0

for i in range(len(new_data.User)):
  for x in males:
      if x in new_data.User[i]:
        new_data['gender'][i] = 'male'
        print(i)

for i in range(len(new_data.User)):
  for x in females:
      if x in new_data.User[i]:
        new_data['gender'][i] = 'female'
        print(f" {x} is in {new_data.User[i]}")

print(len(new_data[new_data.gender == 'male']))

print(len(new_data[new_data.gender == 'female']))

print(len(new_data[new_data.gender == 0]))

from wordcloud import WordCloud
import matplotlib.pyplot as plt
from nltk.tokenize import RegexpTokenizer
from nltk.corpus import stopwords
stopws = stopwords.words('english')
stopws.append('spam , @ , -')  # add any words you don't like to the list

tokenizer = RegexpTokenizer(r'\w+')
#tokens = tokenizer.tokenize(textss)


new_males = new_data[new_data.gender == 'male']
male_texts=  textt = " ".join(review for review in new_males.Text)

#Tokenize the text using the defined tokenizer
tokens = tokenizer.tokenize(male_texts)
tokens = [token for token in tokens if token not in stopws]

wordcloud = WordCloud(stopwords=stopws).generate(male_texts) #takes a while to generate
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.savefig('wordcloud11.png')
plt.show()

new_females = new_data[new_data.gender == 'female']
female_texts=  " ".join(review for review in new_females.Text)

wordcloud = WordCloud(stopwords=stopws).generate(female_texts) #takes a while to generate
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.savefig('wordcloud12.png')
plt.show()

"""### Word Sorting
We plotted a Wordcloud to show the frequnecy of words in females and males. This will not only help us to visually ascertain the similar words that we need to filter out, but it will also give us an idea for our bag of words for each gender.
"""

stopws.extend(["day", "I'm","work","today",'get',"still","going","go","got"])
wordcloud = WordCloud(stopwords=stopws).generate(male_texts) #takes a while to generate
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.savefig('wordcloud11.png')
plt.show()



wordcloud = WordCloud(stopwords=stopws).generate(female_texts) #takes a while to generate
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.savefig('wordcloud11.png')
plt.show()

"""### Punctuation

So we are going to take our classification of females and males and then using a frequency distribution we are going to predict for the unasssigned members what gender they are.
"""

import matplotlib.pyplot as plt
import string
#Function to count punctuation in text
def count_punct(text):
  count = {punct: 0 for punct in string.punctuation}
  for char in text:
      if char in count:
        count[char] += 1
  return count

#count punctuation for male texts
male_counts = count_punct(male_texts)
#count punctuation for female texts
female_counts = count_punct(female_texts)

# prepare data for plotting
punctuation = list(string.punctuation)
male_punct_counts = [male_counts[punct] for punct in punctuation]
female_punct_counts = [female_counts[punct] for punct in punctuation]

#create bar graph
bar_width= 0.35
x = range(len(punctuation))
plt.bar(x, male_punct_counts, width=bar_width, color='blue', label='Male', alpha=0.7)
plt.bar([i + bar_width for i in x], female_punct_counts, width=bar_width, color='red', label='Female', alpha=0.7)
plt.xlabel("Punctuation")
plt.ylabel("Frequency")
plt.title("Frequency of Punctuation in Male and Female Texts")
plt.xticks([i + bar_width / 2 for i in x], punctuation)
plt.legend()
plt.show()

def remove_unecessarys(text):
    final = "".join(u for u in text if u not in ("?", ".", ";", ":",'"',"day", "I'm","work","today",'get',"still","going","go","got"))
    return final
new_males['Text'] = new_males['Text'].apply(remove_unecessarys)
new_females['Text'] = new_females['Text'].apply(remove_unecessarys)

"""### Classification and Predictions
We look at
"""

frames = [new_females,new_males]
merge_data = pd.concat(frames)
null_gender  = new_data[new_data.gender == 0]

final_data = merge_data[['Text','gender']]
null_data = null_gender[['Text', 'gender']]
null_data.tail()

gues = []
#for gender in merge_data.gender:
#  for txt in merge_data.Text(gender):
#    gues.append(list(merge_data.Text(txt)),gender)
for index, row in merge_data.iterrows():
  gender = row['gender']
  text = row['Text']
  gues.append([text,gender])

# create the vocabulary
vocab = set()

# create the bag-of-words model
bow_model = []

for text in final_data.Text:
    # create a dictionary to store the word counts
    word_counts = {}

    # tokenize the text
    tokens = nltk.word_tokenize(text)

    # update the vocabulary
    vocab.update(tokens)

    # count the occurrences of each word
    for word in tokens:
        if word in word_counts:
            word_counts[word] += 1
        else:
            word_counts[word] = 1

    # add the word counts to the bag-of-words model
    bow_model.append(word_counts)

print(bow_model)

"""### Training and Testing the Data"""

train = final_data[:300]
test = final_data[300:1000]
train

from nltk import NaiveBayesClassifier as NBC
from nltk import classify
classifier = NBC.train(train)



"""### Conclusion
Talk about the innacuracies of the initial sorting method and the difficulty of the overall
"""